<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hiroshi Doyu">
<meta name="dcterms.date" content="2024-08-18">
<meta name="description" content="Explore how to build a real-time face identification system using Ultralytics YOLOv8, a state-of-the-art object detection model known for its speed and accuracy. Weâ€™ll compare various tools, including managed services like AWS Rekognition and Azure Face API, to help you choose the best solution for your needs. Whether youâ€™re a developer seeking full control over your models or looking for an easy-to-integrate, scalable solution, this guide will provide you with the knowledge and tools to create a powerful face identification system.">

<title>Building a Real-Time Face Identification System: A Comprehensive Guide â€“ NinjaLABO</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1KVB48YND6"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-1KVB48YND6', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Building a Real-Time Face Identification System: A Comprehensive Guide â€“ NinjaLABO">
<meta name="twitter:description" content="Explore how to build a real-time face identification system using Ultralytics YOLOv8, a state-of-the-art object detection model known for its speed and accuracy. Weâ€™ll compare various tools, including managed services like AWS Rekognition and Azure Face API, to help you choose the best solution for your needs. Whether youâ€™re a developer seeking full control over your models or looking for an easy-to-integrate, scalable solution, this guide will provide you with the knowledge and tools to create a powerful face identification system.">
<meta name="twitter:image" content="https://ninjalabo.github.io/blogs/images/logo.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logo.jpg" alt="NinjaLABO log." class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../getstarted.html" aria-current="page"> 
<span class="menu-text">Get Started</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="../performance.html">
 <span class="dropdown-text">Performance ðŸš€</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorials/runwalkthrough.html">
 <span class="dropdown-text">Tutorials</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../getstarted.html">
 <span class="dropdown-text">Documentations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-company" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Company</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-company">    
        <li>
    <a class="dropdown-item" href="../blogs/about.html">
 <span class="dropdown-text">About</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../blog.html#category=News">
 <span class="dropdown-text">News ðŸŒŸ</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../blog.html">
 <span class="dropdown-text">Blogs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../pricing.html"> 
<span class="menu-text">Pricing</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../getstarted.html"> 
<span class="menu-text"><a href="https://studio.ninjalabo.ai/" style="background-color: rgb(185, 185, 1); padding: 10px 20px; color: white; border: none; border-radius: 0.5rem; text-decoration: None; margin-right: 10px;">Try Free</a></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://twitter.com/ninjalabo" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://www.linkedin.com/company/ninjalabo/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/ninjalabo/ninjalabo.github.io">
            Source Code
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/ninjalabo/ninjalabo.github.io/issues">
            Report a Bug
            </a>
          </li>
      </ul>
    </div>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Building a Real-Time Face Identification System: A Comprehensive Guide</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../blogs/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../getstarted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Get Started</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Tutorials</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorials/runwalkthrough.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Run Walkthrough</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Documentation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">TinyMLaaS - summer 2023</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Architecture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Background information and some literature sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Demonstration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Demonstratation of TinyMLaaS WebApp</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Next_steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Suggestions for further development</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Software-Project-Summer-Kick-off.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project starting point</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Technologies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Technological choices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/TinyML-backend_README.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TinyML-backend</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/TinyML-frontend_README.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TinyML-frontend</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/TinyML-MCU_arduino_README.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Arduino sketch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/TinyML-MCU_README.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TinyML-MCU</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/TinyMLaaS_README.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TinyMLaaS-main</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../docs/tinymlaas/Use_cases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Use case scenarios</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../blog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../performance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Performance</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#step-1-understanding-the-core-requirements" id="toc-step-1-understanding-the-core-requirements" class="nav-link active" data-scroll-target="#step-1-understanding-the-core-requirements"><strong>Step 1: Understanding the Core Requirements</strong></a></li>
  <li><a href="#step-2-choosing-the-right-technology-stack" id="toc-step-2-choosing-the-right-technology-stack" class="nav-link" data-scroll-target="#step-2-choosing-the-right-technology-stack"><strong>Step 2: Choosing the Right Technology Stack</strong></a></li>
  <li><a href="#step-3-implementing-with-ultralytics-yolov8" id="toc-step-3-implementing-with-ultralytics-yolov8" class="nav-link" data-scroll-target="#step-3-implementing-with-ultralytics-yolov8"><strong>Step 3: Implementing with Ultralytics YOLOv8</strong></a>
  <ul class="collapse">
  <li><a href="#setting-up-yolov8" id="toc-setting-up-yolov8" class="nav-link" data-scroll-target="#setting-up-yolov8"><strong>Setting Up YOLOv8</strong></a></li>
  <li><a href="#training-on-a-custom-dataset" id="toc-training-on-a-custom-dataset" class="nav-link" data-scroll-target="#training-on-a-custom-dataset"><strong>Training on a Custom Dataset</strong></a></li>
  <li><a href="#deploying-for-real-time-face-detection" id="toc-deploying-for-real-time-face-detection" class="nav-link" data-scroll-target="#deploying-for-real-time-face-detection"><strong>Deploying for Real-Time Face Detection</strong></a></li>
  </ul></li>
  <li><a href="#step-4-integrating-face-recognition" id="toc-step-4-integrating-face-recognition" class="nav-link" data-scroll-target="#step-4-integrating-face-recognition"><strong>Step 4: Integrating Face Recognition</strong></a></li>
  <li><a href="#step-5-simple-streamlit-ui" id="toc-step-5-simple-streamlit-ui" class="nav-link" data-scroll-target="#step-5-simple-streamlit-ui"><strong>Step 5: Simple Streamlit UI</strong></a></li>
  <li><a href="#step-6-evaluating-alternatives" id="toc-step-6-evaluating-alternatives" class="nav-link" data-scroll-target="#step-6-evaluating-alternatives"><strong>Step 6: Evaluating Alternatives</strong></a></li>
  <li><a href="#step-7-computational-resources" id="toc-step-7-computational-resources" class="nav-link" data-scroll-target="#step-7-computational-resources"><strong>Step 7: Computational resources</strong></a>
  <ul class="collapse">
  <li><a href="#key-factors" id="toc-key-factors" class="nav-link" data-scroll-target="#key-factors">Key Factors:</a></li>
  <li><a href="#calculating-total-fps-requirement" id="toc-calculating-total-fps-requirement" class="nav-link" data-scroll-target="#calculating-total-fps-requirement">Calculating Total FPS Requirement:</a></li>
  <li><a href="#gpu-capacity" id="toc-gpu-capacity" class="nav-link" data-scroll-target="#gpu-capacity">GPU Capacity:</a></li>
  <li><a href="#example-server-configurations" id="toc-example-server-configurations" class="nav-link" data-scroll-target="#example-server-configurations">Example Server Configurations:</a></li>
  <li><a href="#number-of-servers-needed" id="toc-number-of-servers-needed" class="nav-link" data-scroll-target="#number-of-servers-needed">Number of Servers Needed:</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">SUMMARY</a></li>
  </ul></li>
  <li><a href="#step-8-storage-requirement" id="toc-step-8-storage-requirement" class="nav-link" data-scroll-target="#step-8-storage-requirement"><strong>Step 8: Storage Requirement</strong></a>
  <ul class="collapse">
  <li><a href="#key-parameters" id="toc-key-parameters" class="nav-link" data-scroll-target="#key-parameters"><strong>Key Parameters</strong></a></li>
  <li><a href="#storage-calculation" id="toc-storage-calculation" class="nav-link" data-scroll-target="#storage-calculation"><strong>Storage Calculation</strong></a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><strong>Results</strong></a></li>
  <li><a href="#considerations" id="toc-considerations" class="nav-link" data-scroll-target="#considerations"><strong>Considerations</strong></a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1"><strong>SUMMARY</strong></a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><strong>Conclusion</strong></a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ninjalabo/ninjalabo.github.io/edit/main/blogs/yolofaceid.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/ninjalabo/ninjalabo.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Building a Real-Time Face Identification System: A Comprehensive Guide</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Tech</div>
    <div class="quarto-category">UseCase</div>
  </div>
  </div>

<div>
  <div class="description">
    Explore how to build a real-time face identification system using <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a>, a state-of-the-art object detection model known for its speed and accuracy. Weâ€™ll compare various tools, including managed services like <a href="https://aws.amazon.com/rekognition/">AWS Rekognition</a> and <a href="https://azure.microsoft.com/en-us/products/ai-services/ai-vision">Azure Face API</a>, to help you choose the best solution for your needs. Whether youâ€™re a developer seeking full control over your models or looking for an easy-to-integrate, scalable solution, this guide will provide you with the knowledge and tools to create a powerful <strong><em>face identification</em></strong> system.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Hiroshi Doyu <a href="mailto:hiroshi.doyu@ninjalabo.ai" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 18, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>In todayâ€™s world, <strong><em>face identification</em></strong> systems are becoming increasingly crucial in various applications, from security and surveillance to personalized customer experiences. Building a real-time <strong><em>face identification</em></strong> system can seem daunting, but with the right tools and approaches, it becomes manageable. In this article, we will walk you through a project to develop such a system, using some of the best tools available, including <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a>, managed cloud services (e.g.&nbsp;<a href="https://aws.amazon.com/rekognition/">AWS Rekognition</a> and <a href="https://azure.microsoft.com/en-us/products/ai-services/ai-vision">Azure Face API</a>), and more. Weâ€™ll also compare different technologies to help you choose the best one for your needs.</p>
<section id="step-1-understanding-the-core-requirements" class="level1">
<h1><strong>Step 1: Understanding the Core Requirements</strong></h1>
<p>Before diving into the development, itâ€™s essential to outline the core requirements of your <strong><em>face identification</em></strong> system:</p>
<ul>
<li><strong>Real-Time Performance</strong>: The system must detect and identify faces with minimal latency.</li>
<li><strong>Accuracy</strong>: High accuracy in face detection and recognition is crucial, especially in security applications.</li>
<li><strong>Scalability</strong>: Depending on the deployment environment, the system might need to scale to handle multiple video feeds simultaneously.</li>
<li><strong>Ease of Integration</strong>: The system should easily integrate with other components, such as databases and user management systems.</li>
</ul>
</section>
<section id="step-2-choosing-the-right-technology-stack" class="level1">
<h1><strong>Step 2: Choosing the Right Technology Stack</strong></h1>
<p>Choosing the appropriate tools and technologies is critical to meeting the above requirements. Hereâ€™s a comparison of the available options:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Service/Framework</th>
<th>Features</th>
<th>Object Detection</th>
<th>On-Site Deployment</th>
<th>Scalability</th>
<th>Best For</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><a href="https://aws.amazon.com/rekognition/">AWS Rekognition</a></strong></td>
<td>Face detection, recognition, emotion analysis</td>
<td>Yes</td>
<td>No</td>
<td>High (cloud-native, scalable across AWS infrastructure)</td>
<td>Large-scale AWS users, cloud-first deployments</td>
<td>Cost, no native on-site solution</td>
</tr>
<tr class="even">
<td><strong><a href="https://azure.microsoft.com/en-us/products/ai-services/ai-vision">Azure Face API</a></strong></td>
<td>Face detection, attributes, emotion recognition</td>
<td>Yes</td>
<td>Yes (via containers)</td>
<td>High (scales across Azure cloud and on-site with containers)</td>
<td>Microsoft ecosystem, on-site deployment via containers</td>
<td>Cost, limited customization</td>
</tr>
<tr class="odd">
<td><strong><a href="https://cloud.google.com/vision/docs/detecting-faces">Google Cloud Vision</a></strong></td>
<td>Face detection, image classification</td>
<td>Yes</td>
<td>No</td>
<td>High (scales across Google Cloud infrastructure)</td>
<td>Broad vision needs, Google Cloud</td>
<td>Limited face recognition features, no on-site solution</td>
</tr>
<tr class="even">
<td><strong><a href="https://mediacenter.ibm.com/media/IBM+Watson+Visual+Recognition/0_jbsmp6lq">IBM Watson</a></strong></td>
<td>Face detection, customizable models</td>
<td>Yes</td>
<td>Yes</td>
<td>High (scales with IBM cloud or on-premise solutions)</td>
<td>Privacy-conscious industries, on-site solutions</td>
<td>Complexity, cost</td>
</tr>
<tr class="odd">
<td><strong><a href="https://www.faceplusplus.com/">Face++</a></strong></td>
<td>Face detection, beauty score, emotion analysis</td>
<td>Yes</td>
<td>Yes</td>
<td>Moderate (scales well but on-site deployment requires more effort)</td>
<td>Fast, high-accuracy applications, on-site solutions</td>
<td>Privacy concerns, on-site deployment can be complex</td>
</tr>
<tr class="even">
<td><strong><a href="https://www.clarifai.com/use-cases/facial-recognition">Clarifai</a></strong></td>
<td>Face detection, customizable models</td>
<td>Yes</td>
<td>Yes (via on-site SDK)</td>
<td>Moderate (scales well in the cloud, SDK can be scaled on-premises)</td>
<td>Rapid prototyping, easy integration, on-site deployment</td>
<td>Cost, potential latency in cloud deployments</td>
</tr>
<tr class="odd">
<td><strong><a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a></strong></td>
<td>Real-time face detection, fully customizable models</td>
<td>Yes</td>
<td>Yes</td>
<td>High (scales based on deployment environment, requires management)</td>
<td>Developers seeking control, on-site deployment, flexibility</td>
<td>Requires setup and management</td>
</tr>
</tbody>
</table>
<p>Each of these tools has strengths and weaknesses depending on your projectâ€™s needs.</p>
</section>
<section id="step-3-implementing-with-ultralytics-yolov8" class="level1">
<h1><strong>Step 3: Implementing with <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a></strong></h1>
<p>Weâ€™ll focus on using <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a>, given its balance between real-time performance and customization. <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> is well-suited for applications requiring high-speed detection and the flexibility to train on custom datasets.</p>
<p>The real-time <strong><em>face identification</em></strong> system architecture integrates <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a> for face detection with a face recognition model (like <a href="https://en.wikipedia.org/wiki/FaceNet">FaceNet</a>) for identifying individuals. The system processes live video feeds or stored images through <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a>, which detects faces and outputs bounding boxes. These are then passed to a backend server that crops the face images and sends them to the face recognition module. This module generates facial embeddings, compares them against a database of known identities, and identifies the person. The results are displayed in real-time on a client interface, such as a dashboard or alert system.</p>
<p>This architecture can be deployed on-site, ensuring data privacy and low latency, and is designed to scale by adding processing nodes as needed, making it suitable for security, access control, and personalized services.</p>
<p><img src="images/yolov8system.png" class="img-fluid"></p>
<section id="setting-up-yolov8" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-yolov8"><strong>Setting Up <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a></strong></h2>
<ol type="1">
<li><p><strong>Install the Ultralytics Package</strong>: Begin by installing the necessary software using pip:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install ultralytics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Load the <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> Model</strong>: Load a pre-trained <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> model or start with a custom model:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a YOLOv8 model</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> YOLO(<span class="st">'yolov8n.pt'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform inference on an image</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model(<span class="st">'path/to/your/image.jpg'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>results.show()  <span class="co"># Display results</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="training-on-a-custom-dataset" class="level2">
<h2 class="anchored" data-anchor-id="training-on-a-custom-dataset"><strong>Training on a Custom Dataset</strong></h2>
<p>To fine-tune <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> for face detection, you need a dataset of face images with annotations in YOLO format. You can use public datasets like WIDER FACE or CelebA.</p>
<ol type="1">
<li><p><strong>Prepare Your Dataset</strong>: Ensure your dataset is properly annotated and structured.</p></li>
<li><p><strong>Configure and Train the Model</strong>: Train <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> using your dataset:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> YOLO(<span class="st">'yolov8n.pt'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>model.train(data<span class="op">=</span><span class="st">'path/to/data.yaml'</span>, epochs<span class="op">=</span><span class="dv">100</span>, imgsz<span class="op">=</span><span class="dv">640</span>, batch<span class="op">=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="deploying-for-real-time-face-detection" class="level2">
<h2 class="anchored" data-anchor-id="deploying-for-real-time-face-detection"><strong>Deploying for Real-Time Face Detection</strong></h2>
<p>Once trained, you can deploy <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> for real-time face detection. This can be done by feeding live video streams into the model and processing each frame.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the trained model</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> YOLO(<span class="st">'runs/train/exp/weights/best.pt'</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Capture video from webcam</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv2.VideoCapture(<span class="dv">0</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> cap.isOpened():</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform inference</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> model(frame)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display results</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    results.show()</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cv2.waitKey(<span class="dv">1</span>) <span class="op">&amp;</span> <span class="bn">0xFF</span> <span class="op">==</span> <span class="bu">ord</span>(<span class="st">'q'</span>):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>cap.release()</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>cv2.destroyAllWindows()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="step-4-integrating-face-recognition" class="level1">
<h1><strong>Step 4: Integrating Face Recognition</strong></h1>
<p>While <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> handles face detection, <strong><em>face identification</em></strong> (recognition) requires another model. Popular options include FaceNet or ArcFace. After detecting faces, crop the face regions and pass them to a recognition model.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of integrating face recognition after detection</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> result <span class="kw">in</span> results.xyxy[<span class="dv">0</span>]:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    x1, y1, x2, y2, conf, cls <span class="op">=</span> result</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    face_img <span class="op">=</span> frame[<span class="bu">int</span>(y1):<span class="bu">int</span>(y2), <span class="bu">int</span>(x1):<span class="bu">int</span>(x2)]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pass the cropped face to your recognition model</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    face_id <span class="op">=</span> recognize_face(face_img)  <span class="co"># This function would use a recognition model like FaceNet</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="step-5-simple-streamlit-ui" class="level1">
<h1><strong>Step 5: Simple Streamlit UI</strong></h1>
<p>Just an example</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> streamlit <span class="im">as</span> st</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load YOLOv8 model for face detection</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> YOLO(<span class="st">'yolov8n.pt'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Streamlit UI setup</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>st.title(<span class="st">"Real-Time Face Detection"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>st.text(<span class="st">"Streaming live video with YOLOv8 face detection"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># `RTSP` setup (You can use a local webcam or an RTSP stream)</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: 'rtsp://username:password@IP_ADDRESS:PORT/stream1'</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>rtsp_url <span class="op">=</span> st.text_input(<span class="st">"Enter RTSP URL:"</span>, <span class="st">"rtsp://username:password@IP_ADDRESS:PORT/stream1"</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the video capture from RTSP or webcam</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv2.VideoCapture(rtsp_url)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Streamlit video display</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>frame_display <span class="op">=</span> st.empty()</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> cap.isOpened():</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        st.write(<span class="st">"Failed to retrieve frame. Exiting..."</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform face detection using YOLOv8</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> model(frame)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bounding boxes on the frame</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> result <span class="kw">in</span> results.xyxy[<span class="dv">0</span>]:</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        x1, y1, x2, y2, conf, cls <span class="op">=</span> result</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        cv2.rectangle(frame, (<span class="bu">int</span>(x1), <span class="bu">int</span>(y1)), (<span class="bu">int</span>(x2), <span class="bu">int</span>(y2)), (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the frame to RGB (for Streamlit)</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    frame <span class="op">=</span> cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the frame in Streamlit</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    frame_display.image(frame, channels<span class="op">=</span><span class="st">"RGB"</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stop the stream with a button</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> st.button(<span class="st">"Stop Stream"</span>):</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Release the video capture</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>cap.release()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="step-6-evaluating-alternatives" class="level1">
<h1><strong>Step 6: Evaluating Alternatives</strong></h1>
<p>If your project doesnâ€™t require the flexibility of <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> or you want to offload the complexity of training and deployment, consider managed services like AWS Rekognition or Azure Face API. These services are easy to integrate and scale automatically but come at the cost of flexibility and higher operational expenses.</p>
<ul>
<li><strong>AWS Rekognition</strong>: Ideal for applications deeply integrated with AWS, offering face detection, recognition, and emotion analysis.</li>
<li><strong>Azure Face API</strong>: Best for users within the Microsoft ecosystem, offering advanced facial attribute analysis.</li>
<li><strong>Google Cloud Vision</strong>: Suitable for broader computer vision needs beyond face detection.</li>
<li><strong>IBM Watson</strong>: Provides strong privacy features, suitable for industries with strict data regulations.</li>
<li><strong>Face++</strong>: Offers high accuracy and additional features like beauty scoring, though with potential privacy concerns.</li>
</ul>
</section>
<section id="step-7-computational-resources" class="level1">
<h1><strong>Step 7: Computational resources</strong></h1>
<p>To determine how many rack-mount servers youâ€™d need for a face identification system involving 200 cameras using GPUs like the NVIDIA RTX 3080, 3090, or 4090, we need to consider several factors:</p>
<section id="key-factors" class="level2">
<h2 class="anchored" data-anchor-id="key-factors">Key Factors:</h2>
<ol start="0" type="1">
<li><strong>GPU</strong> is superiour to <strong>CPU</strong> at inference from cost vs perf comparison.</li>
<li><strong>Processing Power</strong>: Each GPUâ€™s ability to handle a specific number of frames per second (FPS).</li>
<li><strong>Total FPS Requirement</strong>: The total computational load imposed by the 200 cameras.</li>
<li><strong>Rack-Mount Server Specifications</strong>: The number of GPUs each server can support.</li>
</ol>
</section>
<section id="calculating-total-fps-requirement" class="level2">
<h2 class="anchored" data-anchor-id="calculating-total-fps-requirement">Calculating Total FPS Requirement:</h2>
<ul>
<li><strong>200 Cameras at 30 FPS each</strong>:
<ul>
<li>Total FPS required = 200 cameras * 30 FPS = <strong>6000 FPS</strong>.</li>
</ul></li>
</ul>
</section>
<section id="gpu-capacity" class="level2">
<h2 class="anchored" data-anchor-id="gpu-capacity">GPU Capacity:</h2>
<ul>
<li><strong>NVIDIA RTX 3080</strong>: Can handle approximately 400 FPS for YOLOv8-tiny and around 80-100 FPS for standard YOLOv8.</li>
<li><strong>NVIDIA RTX 3090</strong>: Can handle approximately 600 FPS for YOLOv8-tiny and around 120-150 FPS for standard YOLOv8.</li>
<li><strong>NVIDIA RTX 4090</strong>: Can handle approximately 1000 FPS for YOLOv8-tiny and around 200-250 FPS for standard YOLOv8.</li>
</ul>
</section>
<section id="example-server-configurations" class="level2">
<h2 class="anchored" data-anchor-id="example-server-configurations">Example Server Configurations:</h2>
<ol type="1">
<li><strong>Supermicro 4U GPU Server (SYS-4029GP-TRT)</strong>:
<ul>
<li>Supports up to 4 GPUs.</li>
<li>If each server uses 4x RTX 4090 GPUs, the total processing capability per server would be:
<ul>
<li><strong>YOLOv8-tiny</strong>: 4000 FPS (4 GPUs * 1000 FPS).</li>
<li><strong>Standard YOLOv8</strong>: 800-1000 FPS (4 GPUs * 200-250 FPS).</li>
</ul></li>
</ul></li>
<li><strong>ASUS ESC8000A-E11</strong>:
<ul>
<li>Supports up to 8 GPUs.</li>
<li>With 8x RTX 4090 GPUs:
<ul>
<li><strong>YOLOv8-tiny</strong>: 8000 FPS (8 GPUs * 1000 FPS).</li>
<li><strong>Standard YOLOv8</strong>: 1600-2000 FPS (8 GPUs * 200-250 FPS).</li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="number-of-servers-needed" class="level2">
<h2 class="anchored" data-anchor-id="number-of-servers-needed">Number of Servers Needed:</h2>
<ul>
<li><strong>For YOLOv8-tiny</strong>:
<ul>
<li>With <strong>Supermicro 4U Server</strong>: 1.5 servers (round up to 2 servers).</li>
<li>With <strong>ASUS ESC8000A-E11</strong>: 1 server is sufficient.</li>
</ul></li>
<li><strong>For Standard YOLOv8</strong>:
<ul>
<li>With <strong>Supermicro 4U Server</strong>: 6-8 servers.</li>
<li>With <strong>ASUS ESC8000A-E11</strong>: 3-4 servers.</li>
</ul></li>
</ul>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">SUMMARY</h2>
<ul>
<li><strong>YOLOv8-tiny</strong>: You would need <strong>1-2 servers</strong> (depending on GPU configuration) to handle the 200 cameras.</li>
<li><strong>Standard YOLOv8</strong>: You would need <strong>3-8 servers</strong> depending on the specific GPU and server model you choose.</li>
</ul>
<p>These estimates assume maximum utilization of each GPUâ€™s capabilities, and the actual number might vary based on real-world conditions, such as CPU bottlenecks, memory limitations, and other factors.</p>
</section>
</section>
<section id="step-8-storage-requirement" class="level1">
<h1><strong>Step 8: Storage Requirement</strong></h1>
<p>This outlines the storage requirements for recording video from 200 cameras with resolutions of 2MP and 4MP, continuously over a 30-day period. The calculations take into account various factors such as bitrate, frame rate, and compression method.</p>
<section id="key-parameters" class="level2">
<h2 class="anchored" data-anchor-id="key-parameters"><strong>Key Parameters</strong></h2>
<ul>
<li><strong>Resolution</strong>:
<ul>
<li><strong>2MP (1080p)</strong>: Approximately 3 Mbps</li>
<li><strong>4MP</strong>: Approximately 6 Mbps</li>
</ul></li>
<li><strong>Frame Rate</strong>: 30 frames per second (FPS)</li>
<li><strong>Recording Time</strong>: 24 hours per day, 30 days per month</li>
<li><strong>Number of Cameras</strong>: 200</li>
<li><strong>Compression</strong>: H.264 assumed (H.265 could reduce storage by up to 50%)</li>
</ul>
</section>
<section id="storage-calculation" class="level2">
<h2 class="anchored" data-anchor-id="storage-calculation"><strong>Storage Calculation</strong></h2>
<p>The total storage required can be calculated using the following equation:</p>
<p><span class="math display">\[
\text{Total Storage (TB)} = \left(\frac{\text{Bitrate (Mbps)} \times 86,400 \times 30 \times \text{Number of Cameras}}{8 \times 1024^2}\right)
\]</span></p>
<p>Where:</p>
<ul>
<li><strong>86,400</strong>: Number of seconds in a day</li>
<li><strong>30</strong>: Number of days in a month</li>
<li><strong>8</strong>: Conversion factor from bits to bytes</li>
<li><strong>1024^2</strong>: Conversion from MB to TB</li>
</ul>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results"><strong>Results</strong></h2>
<ol type="1">
<li><strong>For 2MP Cameras (3 Mbps)</strong>:
<ul>
<li><strong>Total Storage</strong>: Approximately <strong>185.2 TB</strong> per month.</li>
</ul></li>
<li><strong>For 4MP Cameras (6 Mbps)</strong>:
<ul>
<li><strong>Total Storage</strong>: Approximately <strong>370.5 TB</strong> per month.</li>
</ul></li>
</ol>
</section>
<section id="considerations" class="level2">
<h2 class="anchored" data-anchor-id="considerations"><strong>Considerations</strong></h2>
<ul>
<li><strong>Compression</strong>: Using H.265 compression could potentially reduce the storage requirement by 50%.</li>
<li><strong>Motion Detection</strong>: If motion detection is used instead of continuous recording, the required storage could be significantly less.</li>
</ul>
</section>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1"><strong>SUMMARY</strong></h2>
<p>For 200 cameras recording continuously at 2-4MP resolution, the storage requirement ranges from approximately <strong>185.2 TB to 370.5 TB per month</strong>. Adjustments to compression methods, frame rates, or recording strategies could alter these estimates.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1><strong>Conclusion</strong></h1>
<p>Building a real-time <strong><em>face identification</em></strong> system requires careful selection of tools and technologies based on your specific requirements. <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLOv8</a> offers a powerful, customizable solution for developers who need control over the face detection process, while managed services like AWS Rekognition and Azure Face API provide easier, scalable alternatives for those looking to avoid the complexities of model training and deployment.</p>
<p>Choosing the right stack involves balancing performance, flexibility, and ease of use. With the tools discussed in this guide, youâ€™re well-equipped to build a robust, real-time <strong><em>face identification</em></strong> system tailored to your needs.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ninjalabo\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2023-2024, NinjaLABO</p>
</div>   
    <div class="nav-footer-center">
<p><strong>Get support</strong></p>
<ul>
<li>For pricing and sales inquiries <a href="mailto:sales@ninjalabo.ai" class="email">sales@ninjalabo.ai</a></li>
<li>Ask tech questions <a href="mailto:help@ninjalabo.ai" class="email">help@ninjalabo.ai</a></li>
</ul>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ninjalabo/ninjalabo.github.io/edit/main/blogs/yolofaceid.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/ninjalabo/ninjalabo.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Helsinki, Finland
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ninjalabo">
      <i class="bi bi-twitter" role="img" aria-label="NinjaLABO Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/company/ninjalabo/">
      <i class="bi bi-linkedin" role="img" aria-label="NinjaLABO LinkedIn">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ninjalabo/ninjalabo.github.io">
      <i class="bi bi-github" role="img" aria-label="NinjaLABO GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>