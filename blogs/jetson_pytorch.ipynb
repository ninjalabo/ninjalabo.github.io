{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"How to Easily Install PyTorch on Jetson Orin Nano (JetPack 6.2)\"\n",
    "description: \"Follow this step-by-step guide to install PyTorch on the Jetson Orin Nano running JetPack 6.2.\"\n",
    "author: \n",
    " - name: \"Nghi Vo Dong\"\n",
    "   email: nghi.vo@ninjalabo.ai\n",
    "date: \"02/27/2025\"\n",
    "draft: false\n",
    "categories:\n",
    "  - Tech\n",
    "  - Jetson\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA Jetson devices offer powerful AI inference capabilities at the edge, making them ideal for running deep learning models efficiently. This guide provides step-by-step instructions to set up an [NVIDIAÂ® Jetson Orin Nanoâ„¢ Developer Kit](https://developer.nvidia.com/embedded/learn/jetson-orin-nano-devkit-user-guide/index.html) for deep learning with PyTorch and torchvision. The installation process will be performed via a terminal from a host machine connected through USB or a serial connection. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software and Package Versions**\n",
    "\n",
    "This guide involves the following software and package versions for setting up PyTorch on the Jetson Orin Nano:\n",
    "\n",
    "- **JetPack** - 6.2 (also compatible with 6.1)  \n",
    "- **CUDA** - 12.6  \n",
    "- **Python** - 3.10  \n",
    "- **cuSPARSELt** - 0.7.0  \n",
    "- **torch** - 2.5.0a0+872d972e41 ([NVIDIA wheel](https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch)).  \n",
    "- **torchvision** - 0.20.0 (built from source)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Headless setup - WIFI connection and IP address\n",
    "\n",
    "If your Jetson device is controlled via headless setup, here are some instructions to connect to Wifi using `nmcli`:\n",
    "\n",
    "1. Check available WiFi networks: `nmcli device wifi list`  \n",
    "2. Connect to a WiFi network: `nmcli device wifi connect \"SSID_NAME\" password \"YOUR_PASSWORD\"`  \n",
    "3. Verify the Connection: `nmcli connection show --active`\n",
    "\n",
    "Note: If encountering unauthorized error, add `sudo` before these commands.\n",
    "\n",
    "After connecting to WIFI, the user can retrieve the IP address assigned to the Jetson device. Check the active connections with the command in step 3, which should output their names, UUIDs, types, and devices. Notice the device of the WIFI (type) connection and use it with the command `ip a show <DEVICE_NAME>`. From another device, e.g., host machine, that also connects to this WIFI, verify the connection to Jetson by using `ping` on this IP address. By securing this connection, the user can easily share files, servers, and CLI session from Jetson device to host machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Installing JetPack and SDK Components\n",
    "\n",
    "The Jetson device must be flashed with JetPack, which includes the Jetson Linux OS and necessary GPU computing libraries such as CUDA and cuDNN. Follow the official [NVIDIA JetPack installation guide](https://developer.nvidia.com/embedded/jetpack-sdk-62) for instructions. Ensure that firmware version is updated to 36+ for JetPack > 6.\n",
    "\n",
    "To flash Jetson Orin Nano, install [NVIDIA SDK Manager](https://docs.nvidia.com/sdk-manager/index.html) on a Linux host machine and follow the setup steps. During flashing, select Jetson SDK Components to install CUDA toolkit in the [second step](https://docs.nvidia.com/sdk-manager/install-with-sdkm-jetson/index.html#step-02-review-components-and-accept-licenses). If CUDA is missing post-installation, follow the JetPack [package management guide](https://docs.nvidia.com/jetson/jetpack/install-setup/index.html#package-management-tool).\n",
    "\n",
    "CUDA installation can be verified with -\n",
    "```sh\n",
    "$ nvcc --version\n",
    "```\n",
    "or\n",
    "```sh\n",
    "$ nvidia-smi\n",
    "```\n",
    "which should show the same CUDA version.\n",
    "\n",
    "For additional verification, compile and run a CUDA sample from its Github repository:\n",
    "```sh\n",
    "# Clone suitable version for testing CUDA 12.6 \n",
    "$ git clone --branch v12.5 https://github.com/NVIDIA/cuda-samples.git\n",
    "$ cd cuda-samples/Samples/1_Utilities/deviceQuery\n",
    "$ make\n",
    "$ ./deviceQuery\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Installing PyTorch and torchvision\n",
    "\n",
    "Jetson devices use integrated GPUs (iGPUs) while default CUDA backend of PyTorch is optimized for discrete GPUs (dGPUs). To enable PyTorch with GPU acceleration on Jetson, follow the custom installation available in [NVIDIA instructions](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform/index.html) and [NVIDIA forums](https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048). The supporting package torchvision also has to be built from source on the Jetson device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing cuSPARSELt\n",
    "\n",
    "For PyTorch versions 24.06+ (see [Compatibility Matrix](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform-release-notes/pytorch-jetson-rel.html#pytorch-jetson-rel)), cuSPARSELt is required. Install it with these [instructions](https://developer.nvidia.com/cusparselt-downloads) by selecting Linux OS, aarch64-jetson architecture, and Ubuntu distribution:\n",
    "```sh\n",
    "$ wget https://developer.download.nvidia.com/compute/cusparselt/0.7.0/local_installers/cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n",
    "$ sudo dpkg -i cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n",
    "$ sudo cp /var/cusparselt-local-tegra-repo-ubuntu2204-0.7.0/cusparselt-*-keyring.gpg /usr/share/keyrings/\n",
    "$ sudo apt-get update\n",
    "$ sudo apt-get -y install libcusparselt0 libcusparselt-dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "(Optional) Create a virtual environment:\n",
    "\n",
    "```sh\n",
    "$ sudo apt-get install virtualenv\n",
    "$ cd <target-directory>\n",
    "$ python3 -m virtualenv -p python3 <venv-name>\n",
    "$ source <venv-name>/bin/activate\n",
    "```\n",
    "\n",
    "Install PyTorch with a custom wheel built by NVIDIA:  \n",
    "\n",
    "1. Check compatibility from [NVIDIA Jetson PyTorch matrix](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform-release-notes/pytorch-jetson-rel.html).  \n",
    "2. Select suitable wheel from [list of released wheels](https://developer.download.nvidia.com/compute/redist/jp/) by selecting `v$JP_VERSION` (JetPack version) > `pytorch` > `$PYT_VERSION ... .whl` (PyTorch version).  \n",
    "3. Install with pip - \n",
    "```sh\n",
    "$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v$JP_VERSION/pytorch/$PYT_VERSION ... .whl\n",
    "```\n",
    "\n",
    "In this tutorial, PyTorch version 2.5 for JetPack 6.1 (still compatible with 6.2) will be installed with:\n",
    "```sh\n",
    "$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch/torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl\n",
    "```\n",
    "\n",
    "Verify with Python Terminal:\n",
    "```sh\n",
    "$ python3\n",
    ">>> import torch\n",
    ">>> print(torch.__version__)\n",
    ">>> print('CUDA available: ' + str(torch.cuda.is_available()))  # Should be True\n",
    ">>> print('cuDNN version: ' + str(torch.backends.cudnn.version()))\n",
    ">>> a = torch.cuda.FloatTensor(2).zero_()\n",
    ">>> print('Tensor a = ' + str(a))\n",
    ">>> b = torch.randn(2).cuda()\n",
    ">>> print('Tensor b = ' + str(b))\n",
    ">>> c = a + b\n",
    ">>> print('Tensor c = ' + str(c))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing torchvision\n",
    "\n",
    "torchvision must be built from source. Select a compatible version of torchvision from [PyTorch releases](https://pytorch.org/get-started/previous-versions/) and replaces `$VERSION` in the following commands:\n",
    "\n",
    "```sh\n",
    "$ sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libopenblas-dev libavcodec-dev libavformat-dev libswscale-dev\n",
    "$ git clone --branch release/0.$VERSION https://github.com/pytorch/vision torchvision\n",
    "$ cd torchvision\n",
    "$ export BUILD_VERSION=0.$VERSION.0\n",
    "$ python3 setup.py install --user # remove --user if installing in virtualenv\n",
    "```\n",
    "\n",
    "In this tutorial, torchvision version 0.20.0 is installed by replacing `$VERSION` with 20.\n",
    "\n",
    "Verify with Python terminal:\n",
    "```sh\n",
    "$ python3\n",
    ">>> import torchvision\n",
    ">>> print(torchvision.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "Here are some known issues and tips for troubleshooting:\n",
    "\n",
    "- If a warning about numpy version is show, downgrade to numpy with `pip install 'numpy<2'`  \n",
    "- If you encounter this runtime error - `RuntimeError: operator torchvision::nms does not exist`, follow the instructions in [this NVIDIA forum post](https://forums.developer.nvidia.com/t/pytorch-and-torvision-version-issue-runtimeerror-operator-torchvision-nms-does-not-exist/312446). Specifically, install these pre-compiled binaries of `torch` and `torchvision`:\n",
    "\n",
    "```sh\n",
    "$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5cf/9ed17e35cb752/torch-2.5.0-cp310-cp310-linux_aarch64.whl#sha256=5cf9ed17e35cb7523812aeda9e7d6353c437048c5a6df1dc6617650333049092\n",
    "$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5f9/67f920de3953f/torchvision-0.20.0-cp310-cp310-linux_aarch64.whl#sha256=5f967f920de3953f2a39d95154b1feffd5ccc06b4589e51540dc070021a9adb9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - (Optional) Setting up Jupyter Notebook for Remote Access via SSH tunnel\n",
    "If your Jetson device is connected to the same network as your other machinesâ€”or directly via USB or a serial cableâ€”you can start a remote Jupyter server from the Jetson device for convenient headless operations. First, find the IP address of your Jetson device:\n",
    "\n",
    "```sh\n",
    "$ ip a\n",
    "```  \n",
    "\n",
    "Look for an IP address similar to 192.168.x.x or 10.x.x.x.\n",
    "\n",
    "(Optional) Control Jetson terminal via SSH. Log in with Jetson username (user of Linux OS running on Jetson) and enter password when prompted.  \n",
    "\n",
    "```sh\n",
    "$ ssh <jetson-username>@<jetson-ip>\n",
    "```\n",
    "\n",
    "Install Jupyterlab or Jupyter Notebook on Jetson terminal (or SSH session):\n",
    "\n",
    "```sh\n",
    "$ pip install jupyterlab\n",
    "$ pip isntall notebook\n",
    "```\n",
    "\n",
    "Start server from Jetson terminal (or SSH session):\n",
    "\n",
    "```sh\n",
    "$ jupyter notebook --no-browser --port=8888 --ip=0.0.0.0\n",
    "```  \n",
    "\n",
    "From your local PC, forward port 8888 using SSH:\n",
    "\n",
    "```sh\n",
    "ssh -N -L 8888:localhost:8888 <jetson-username>@<jetson-ip>\n",
    "```\n",
    "\n",
    "And access running Jupyter server with localhost on your PC: `http://localhost:8888/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following this guide, you've successfully installed PyTorch and torchvision on your Jetson Orin Nano running JetPack 6.2. With this setup, your device is now prepared for deep learning tasks, AI model deployment, and edge computing applications. This installation is part of our comprehensive walkthrough on running ResNet18 with fastai on the Jetson Orin Nanoâ€”check out the [full tutorial here](https://ninjalabo.ai/jetson-examples/fastai.html) if you're interested!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
