{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5d460b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Knowledge Distillation Implementation 2/3\"\n",
    "description: \"2. Hint-Based Distillation\"\n",
    "author: \n",
    " - name: \"Leila Mozaffari\"\n",
    "   email: leila.mozaffari@ninjalabo.ai\n",
    "date: \"10/10/2024\"\n",
    "draft: false\n",
    "categories:\n",
    "  - Tech\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf534e",
   "metadata": {},
   "source": [
    "# 2.Hint-Based Distillation (Intermediate Feature Matching) technique \n",
    "\n",
    "\n",
    "\n",
    "![](img/Hint.png)\n",
    "\n",
    "\n",
    "### Reference:\n",
    "* Romero, A., Ballas, N., Kahou, S. E., Chassang, A., Gatta, C., & Bengio, Y. (2015). FitNets: Hints for Thin Deep Nets. arXiv preprint arXiv:1412.6550. Retrieved from https://arxiv.org/abs/1412.6550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Define transforms for data augmentation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load the Imagenette2-320 dataset\n",
    "data_dir = './data/imagenette2-320/imagenette2-320'\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde369d",
   "metadata": {},
   "source": [
    "## Define Teacher and Student Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f6e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained teacher (ResNet50) and student (ResNet18)\n",
    "teacher_model = models.resnet50(pretrained=True)\n",
    "student_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Adjust final layers to match number of classes in Imagenette (10 classes)\n",
    "num_ftrs_teacher = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(num_ftrs_teacher, 10)\n",
    "\n",
    "num_ftrs_student = student_model.fc.in_features\n",
    "student_model.fc = nn.Linear(num_ftrs_student, 10)\n",
    "\n",
    "# Move models to the appropriate device (GPU if available)\n",
    "teacher_model = teacher_model.to(device)\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "# Set teacher model to evaluation mode (as it is not being trained)\n",
    "teacher_model.eval()\n",
    "\n",
    "# Define 1x1 convolution to match the dimensions between teacher and student feature maps\n",
    "# Assuming teacher's layer3 outputs 1024 channels and student's layer3 outputs 256 channels\n",
    "\n",
    "conv_teacher_to_student = nn.Conv2d(1024, 256, kernel_size=1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49ec52",
   "metadata": {},
   "source": [
    "## Extract Intermediate Feature Representations\n",
    "\n",
    "We need to extract intermediate features from both the teacher and the student models. One way to achieve this is by using forward hooks in PyTorch to capture activations at specific layers. In this case, we’ll extract features from a chosen layer in both models, for example, the output of the third residual block in both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239360b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x21cb76104c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to register a hook for feature extraction\n",
    "def extract_features(module, input, output):\n",
    "    return output\n",
    "\n",
    "# Extract features from the third residual block (layer3) for both models\n",
    "teacher_features = []\n",
    "student_features = []\n",
    "\n",
    "def register_hooks(model, features_storage):\n",
    "    def hook(module, input, output):\n",
    "        features_storage.append(output)\n",
    "    return hook\n",
    "\n",
    "# Register hook to extract features from teacher model (layer3 output)\n",
    "teacher_model.layer3[5].register_forward_hook(register_hooks(teacher_model, teacher_features))\n",
    "\n",
    "# Register hook to extract features from student model (layer3 output)\n",
    "student_model.layer3[1].register_forward_hook(register_hooks(student_model, student_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d91665",
   "metadata": {},
   "source": [
    "## Define the Custom Distillation Loss\n",
    "\n",
    "e now define a custom loss function that combines:\n",
    "\n",
    "* 1. Cross-Entropy Loss on the student’s hard predictions against the ground truth labels.\n",
    "* 2. KL Divergence Loss between the teacher's and student’s soft logits (output of final layer).\n",
    "* 3. Feature Matching Loss (e.g., L2 loss) between the intermediate feature maps of the teacher and student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3117a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HintBasedDistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature=3.0, alpha=0.5, beta=0.5):\n",
    "        super(HintBasedDistillationLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.l2_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, student_features, teacher_features, labels):\n",
    "        # Soft targets: apply temperature scaling to teacher outputs\n",
    "        teacher_soft = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        student_soft = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
    "\n",
    "        # Distillation loss (KL divergence between student and teacher's softened outputs)\n",
    "        distillation_loss = self.kl_div_loss(student_soft, teacher_soft) * (self.temperature ** 2)\n",
    "\n",
    "        # Cross entropy loss (between student predictions and true labels)\n",
    "        student_loss = self.ce_loss(student_logits, labels)\n",
    "\n",
    "        # Feature matching loss (L2 loss between teacher and student feature maps)\n",
    "        feature_loss = self.l2_loss(student_features, teacher_features)\n",
    "\n",
    "        # Combined loss\n",
    "        return self.alpha * distillation_loss + (1.0 - self.alpha) * student_loss + self.beta * feature_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79fd3f",
   "metadata": {},
   "source": [
    "## Implement the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736043f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student(teacher_model, student_model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = student_model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Set student model to training mode\n",
    "        student_model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the data\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Clear gradients for student model\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Clear the feature lists before every forward pass\n",
    "            teacher_features.clear()  # Clear saved teacher features\n",
    "            student_features.clear()  # Clear saved student features\n",
    "\n",
    "            # Forward pass through teacher (for soft labels and features)\n",
    "            with torch.no_grad():  # Disable gradients for teacher model\n",
    "                teacher_logits = teacher_model(inputs)\n",
    "                teacher_feature = teacher_features[0]  # Extract intermediate feature from teacher\n",
    "\n",
    "            # Forward pass through student\n",
    "            student_logits = student_model(inputs)\n",
    "            student_feature = student_features[0]  # Extract intermediate feature from student\n",
    "\n",
    "            # Apply 1x1 convolution to match teacher's feature map dimensions to student's\n",
    "            teacher_feature_resized = conv_teacher_to_student(teacher_feature)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(student_logits, teacher_logits, student_feature, teacher_feature_resized, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()  # Compute gradients only for the student model\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute running statistics\n",
    "            _, preds = torch.max(student_logits, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "\n",
    "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Deep copy the model\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = student_model.state_dict()\n",
    "\n",
    "    # Training complete\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    student_model.load_state_dict(best_model_wts)\n",
    "    return student_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9a945",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1b070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Loss: 0.6921 Acc: 0.8747\n",
      "Epoch 1/4\n",
      "----------\n",
      "Loss: 0.6239 Acc: 0.9241\n",
      "Epoch 2/4\n",
      "----------\n",
      "Loss: 0.6072 Acc: 0.9267\n",
      "Epoch 3/4\n",
      "----------\n",
      "Loss: 0.5918 Acc: 0.9378\n",
      "Epoch 4/4\n",
      "----------\n",
      "Loss: 0.5790 Acc: 0.9413\n",
      "Training complete in 98m 5s\n",
      "Best Acc: 0.9413\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Define hint-based distillation loss\n",
    "criterion = HintBasedDistillationLoss(temperature=3.0, alpha=0.5, beta=0.5)\n",
    "\n",
    "# Train the student model\n",
    "trained_student = train_student(teacher_model, student_model, dataloaders, criterion, optimizer, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f75c34",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f393df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloaders):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad(): # No need to compute gradients during evaluation\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate trained student model\n",
    "evaluate_model(trained_student, dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69977c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
