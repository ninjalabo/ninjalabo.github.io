{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3e6e02",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Knowledge Distillation Implementation 1/3\"\n",
    "description: \"1. Soft Label Distillation\"\n",
    "author: \n",
    " - name: \"Leila Mozaffari\"\n",
    "   email: leila.mozaffari@ninjalabo.ai\n",
    "date: \"10/10/2024\"\n",
    "draft: false\n",
    "categories:\n",
    "  - Tech\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d26a5",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4a0aa",
   "metadata": {},
   "source": [
    "## 1. Knowledge Distillation technique using Soft Targets, also known as Soft Label Distillation or Logits Distillation. \n",
    "\n",
    "Soft Targets (Logits Distillation): The student model is trained not only on the hard labels (i.e., the ground truth labels), but also on the soft targets provided by the teacher model. The soft targets are the probabilities output by the teacher model after applying a temperature scaling to the logits (pre-softmax outputs).\n",
    "\n",
    "An intuitive example of hard and soft targets for knowledge distillation:\n",
    "\n",
    "\n",
    "The output of the network with no activation function is Logit.\n",
    "\n",
    "![](images/Logit.png)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Soft Label \n",
    "\n",
    "\n",
    "![](images/Soft_Labels.png)\n",
    "\n",
    "\n",
    "### Temperature (T):\n",
    "Think of the temperature as a dial that controls how \"sharp\" or \"smooth\" the teacher model's predictions are. Normally, when a model makes predictions, it assigns high confidence to one class (the correct one) and very low confidence to others. This results in a \"spiky\" output, where one class has a high probability, and all others are close to zero.\n",
    "\n",
    "\n",
    "![](images/Temperature.png)\n",
    "\n",
    "\n",
    "### Softening:\n",
    "\"Softening\" refers to this process of making the output probabilities smoother (less sharp) when the temperature is increased. It’s called softening because the output becomes \"softer\" and less certain, giving some probability to even incorrect classes. This softened output is called soft targets.\n",
    "\n",
    "### Reference:\n",
    "\n",
    "* Hinton, G., Vinyals, O., & Dean, J. (2015). Distilling the Knowledge in a Neural Network. arXiv preprint arXiv:1503.02531. Retrieved from https://arxiv.org/abs/1503.02531\n",
    "* https://www.youtube.com/watch?v=zhrfBCNSO1Q\n",
    "* https://www.youtube.com/watch?v=G0_lB1Ce65c&list=PLRhS6hiNUzERWXK6KE150aS8MJg-sVUCB&index=2\n",
    "* https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de04877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eff3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454d343",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    " \n",
    "Preprocess the Imagenette2-320 dataset. Apply transforms to the images (resizing, normalization, etc.).\n",
    "\n",
    "\n",
    "The input images are RGB, so they have 3 channels and are 32x32 pixels. Basically, each image is described by 3 x 32 x 32 = 3072 numbers ranging from 0 to 255. A common practice in neural networks is to normalize the input, which is done for multiple reasons, including avoiding saturation in commonly used activation functions and increasing numerical stability. Our normalization process consists of subtracting the mean and dividing by the standard deviation along each channel. The tensors “mean=[0.485, 0.456, 0.406]” and “std=[0.229, 0.224, 0.225]” were already computed, and they represent the mean and standard deviation of each channel in the predefined subset of dataset intended to be the training set. (https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b127f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing and Augmentation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load Dataset\n",
    "data_dir =  './data/imagenette2-320/imagenette2-320'\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d9579",
   "metadata": {},
   "source": [
    "## Define the Teacher and Student Models: teacher (ResNet50) and student (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e3f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\layal/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a4acc3339d4565884477e982010d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\layal/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2416798d1381474c999a62bcf24b263b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Teacher (ResNet50) and Student (ResNet18)\n",
    "teacher_model = models.resnet50(pretrained=True)\n",
    "student_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last layer to match the number of classes (Imagenette has 10 classes)\n",
    "num_ftrs_teacher = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(num_ftrs_teacher, 10)\n",
    "\n",
    "num_ftrs_student = student_model.fc.in_features\n",
    "student_model.fc = nn.Linear(num_ftrs_student, 10)\n",
    "\n",
    "# Move models to the appropriate device (GPU if available)\n",
    "teacher_model = teacher_model.to(device)\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "# Set teacher to evaluation mode, as its weights are frozen\n",
    "teacher_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b8bc6",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Loss\n",
    "\n",
    "Distillation Loss: The loss function used combines:\n",
    "\n",
    "* Cross-Entropy Loss (Hard Labels): This is the standard supervised learning loss between the student model's predictions and the true labels.\n",
    "* Kullback-Leibler (KL) Divergence Loss (Soft Labels): This measures how closely the student model's softened output distribution aligns with the teacher's softened output distribution.\n",
    "\n",
    "### Formula Used for Knowledge Distillation Loss:\n",
    "\n",
    "The distillation loss function is expressed as:\n",
    "\n",
    "$$\n",
    "L_{\\text{KD}} = \\alpha \\cdot T^2 \\cdot \\text{KL}(p_{\\text{teacher}}, p_{\\text{student}}) + (1 - \\alpha) \\cdot L_{\\text{CE}}(y_{\\text{true}}, p_{\\text{student}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $p_{\\text{teacher}}$ is the soft probability distribution from the teacher model.\n",
    "\n",
    "* $p_{\\text{student}}$ is the soft probability distribution from the student model.\n",
    "\n",
    "* $L_{\\text{CE}}$ is the cross-entropy loss.\n",
    "\n",
    "* $\\alpha$ is a hyperparameter to control the contribution of the soft targets.\n",
    "\n",
    "* $T$ is the temperature scaling factor applied to both teacher and student logits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040c9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature=3.0, alpha=0.5):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, labels):\n",
    "        # Soft targets: apply temperature scaling to teacher outputs\n",
    "        teacher_soft = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        student_soft = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
    "\n",
    "        # Distillation loss (KL divergence between student and teacher's softened outputs)\n",
    "        distillation_loss = self.kl_div_loss(student_soft, teacher_soft) * (self.temperature ** 2)\n",
    "\n",
    "        # Cross entropy loss (between student predictions and true labels)\n",
    "        student_loss = self.ce_loss(student_logits, labels)\n",
    "\n",
    "        # Combined loss\n",
    "        return self.alpha * distillation_loss + (1.0 - self.alpha) * student_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80508289",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e6e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student(teacher_model, student_model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = student_model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training phase\n",
    "        student_model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through both teacher and student\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(student_outputs, teacher_outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            _, preds = torch.max(student_outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "\n",
    "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Copy the best model\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = student_model.state_dict()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    student_model.load_state_dict(best_model_wts)\n",
    "    return student_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6cbc7",
   "metadata": {},
   "source": [
    "## Optimizer and Hyperparameters\n",
    "\n",
    "* **SGD** is a popular optimizer for training neural networks and has been widely used in training large architectures like ResNet. It's particularly good at providing a regularized, stable learning process when the learning rate is tuned properly. It avoids overfitting and promotes generalization when combined with momentum.\n",
    "* **Momentum** (0.9) helps in accelerating gradients and converging faster by averaging out noise in gradient updates, preventing the optimizer from oscillating as much.\n",
    "* **Learning Rate** 0.01 is a common learning rate for large-scale training tasks with SGD. It is not too large to cause unstable updates, nor too small to slow down learning excessively.\n",
    "* **Temperature** scaling is used to control the softness of the teacher model’s output probability distribution. Higher temperatures produce softer probability distributions, revealing more about the relationships between different classes. A value of 3.0 is commonly used in knowledge distillation to smooth out the logits from the teacher model and make the student focus more on the relative probabilities assigned by the teacher model, rather than just the highest-probability class.\n",
    "* **Alpha** controls the balance between the soft labels (from the teacher) and the hard labels (from the ground truth). A value of 0.5 equally weights the contribution from both the distillation loss (soft labels) and the cross-entropy loss (hard labels). This balance is crucial when training on datasets like Imagenette, where both the ground truth labels and the teacher’s soft predictions carry valuable information.\n",
    "You may adjust this value depending on how much you want the student model to prioritize learning from the teacher versus learning from the original ground truth. For example:\n",
    "If the teacher’s knowledge is highly reliable, you might increase alpha (> 0.5) to emphasize learning from the teacher’s soft targets.\n",
    "If the ground truth labels are of high quality, you might decrease alpha (< 0.5) to rely more on the hard labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6b677c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "Loss: 0.6731 Acc: 0.8762\n",
      "Epoch 1/24\n",
      "----------\n",
      "Loss: 0.6200 Acc: 0.9182\n",
      "Epoch 2/24\n",
      "----------\n",
      "Loss: 0.5981 Acc: 0.9310\n",
      "Epoch 3/24\n",
      "----------\n",
      "Loss: 0.5907 Acc: 0.9364\n",
      "Epoch 4/24\n",
      "----------\n",
      "Loss: 0.5797 Acc: 0.9427\n",
      "Epoch 5/24\n",
      "----------\n",
      "Loss: 0.5728 Acc: 0.9468\n",
      "Epoch 6/24\n",
      "----------\n",
      "Loss: 0.5677 Acc: 0.9465\n",
      "Epoch 7/24\n",
      "----------\n",
      "Loss: 0.5639 Acc: 0.9492\n",
      "Epoch 8/24\n",
      "----------\n",
      "Loss: 0.5581 Acc: 0.9494\n",
      "Epoch 9/24\n",
      "----------\n",
      "Loss: 0.5515 Acc: 0.9538\n",
      "Epoch 10/24\n",
      "----------\n",
      "Loss: 0.5536 Acc: 0.9537\n",
      "Epoch 11/24\n",
      "----------\n",
      "Loss: 0.5467 Acc: 0.9586\n",
      "Epoch 12/24\n",
      "----------\n",
      "Loss: 0.5463 Acc: 0.9554\n",
      "Epoch 13/24\n",
      "----------\n",
      "Loss: 0.5459 Acc: 0.9559\n",
      "Epoch 14/24\n",
      "----------\n",
      "Loss: 0.5440 Acc: 0.9566\n",
      "Epoch 15/24\n",
      "----------\n",
      "Loss: 0.5399 Acc: 0.9611\n",
      "Epoch 16/24\n",
      "----------\n",
      "Loss: 0.5358 Acc: 0.9637\n",
      "Epoch 17/24\n",
      "----------\n",
      "Loss: 0.5318 Acc: 0.9639\n",
      "Epoch 18/24\n",
      "----------\n",
      "Loss: 0.5336 Acc: 0.9612\n",
      "Epoch 19/24\n",
      "----------\n",
      "Loss: 0.5262 Acc: 0.9666\n",
      "Epoch 20/24\n",
      "----------\n",
      "Loss: 0.5318 Acc: 0.9631\n",
      "Epoch 21/24\n",
      "----------\n",
      "Loss: 0.5313 Acc: 0.9622\n",
      "Epoch 22/24\n",
      "----------\n",
      "Loss: 0.5245 Acc: 0.9678\n",
      "Epoch 23/24\n",
      "----------\n",
      "Loss: 0.5258 Acc: 0.9657\n",
      "Epoch 24/24\n",
      "----------\n",
      "Loss: 0.5243 Acc: 0.9640\n",
      "Training complete in 517m 41s\n",
      "Best Acc: 0.967790\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer for the student model\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Define the distillation loss\n",
    "criterion = DistillationLoss(temperature=3.0, alpha=0.5)\n",
    "\n",
    "# Train the student model\n",
    "trained_student = train_student(teacher_model, student_model, dataloaders, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffad4e2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a391f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloaders):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad(): # No need to compute gradients during evaluation\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate trained student model\n",
    "evaluate_model(trained_student, dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b90cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
