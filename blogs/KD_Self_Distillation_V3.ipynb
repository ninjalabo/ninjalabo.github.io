{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80249663",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Knowledge Distillation Implementation 3/3\"\n",
    "description: \"3. Self-Distillation\"\n",
    "author: \n",
    " - name: \"Leila Mozaffari\"\n",
    "   email: leila.mozaffari@ninjalabo.ai\n",
    "date: \"10/10/2024\"\n",
    "draft: false\n",
    "categories:\n",
    "  - Tech\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21146c7d",
   "metadata": {},
   "source": [
    "# 3. Self-Distillation\n",
    "\n",
    "\n",
    "**Self-distillation** is a technique in which a model distills knowledge into itself. In this case, the same model is used both as a teacher and a student, a process where intermediate layers' outputs help guide earlier layers in the same model. The idea is that the student network learns from itself by taking advantage of various self-regularization strategies, and intermediate outputs can be utilized for knowledge transfer.\n",
    "\n",
    "In this case, instead of the classical teacher-student approach, we'll consider ResNet18, with the student learning from its own intermediate outputs. Self-distillation usually results in a student model that generalizes better without needing an external teacher.\n",
    "\n",
    "\n",
    "![](img/Self_Distillation.png)\n",
    "\n",
    "\n",
    "### References\n",
    "* J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge Distillation: A Survey,” May 20, 2021, arXiv: arXiv:2006.05525. doi: 10.48550/arXiv.2006.05525. https://arxiv.org/abs/2006.05525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9768560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "# Define image transformations for training and validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load Imagenette2-320 dataset\n",
    "data_dir = './data/imagenette2-320/imagenette2-320'\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbbad53",
   "metadata": {},
   "source": [
    "## Define Models\n",
    "\n",
    "\n",
    "This 1x1 convolution layer reduces the number of channels from 512 (layer4 output in ResNet18) to 128 (layer2 output) to ensure compatibility when comparing the feature maps from these two layers in the distillation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b25928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet18 model (used as the student)\n",
    "student_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last layer to match the number of classes in Imagenette (10 classes)\n",
    "num_ftrs_student = student_model.fc.in_features\n",
    "student_model.fc = nn.Linear(num_ftrs_student, 10)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "\n",
    "# Define a 1x1 convolution to match the number of channels\n",
    "conv1x1 = nn.Conv2d(512, 128, kernel_size=1).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f3063",
   "metadata": {},
   "source": [
    "## Self-Distillation Strategy\n",
    "\n",
    "**Feature Extraction Hooks**\n",
    "\n",
    "* **Hooks**: Forward hooks are used to extract the intermediate feature maps from layer2 and layer4 of ResNet18 during the forward pass. The extracted features are stored in the intermediate_features dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82d4f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2bb98f80f10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to register hooks and extract intermediate features\n",
    "def get_intermediate_features(module, input, output):\n",
    "    return output\n",
    "\n",
    "# Dictionaries to store the intermediate features during forward pass\n",
    "intermediate_features = {}\n",
    "\n",
    "# Register forward hooks to capture features from desired layers\n",
    "student_model.layer2[1].register_forward_hook(lambda m, i, o: intermediate_features.update({\"layer2\": o}))\n",
    "student_model.layer4[1].register_forward_hook(lambda m, i, o: intermediate_features.update({\"layer4\": o}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704a1cc",
   "metadata": {},
   "source": [
    "## Custom Self-Distillation Loss\n",
    "\n",
    "* **Cross-Entropy Loss (ce_loss)**: Computes the loss between the predicted class labels (logits) and the ground truth labels.\n",
    "* **MSE Loss (distillation_loss)**: Encourages the student model to match its intermediate feature maps (layer2) with those of the deeper layers (layer4) by applying Mean Squared Error.\n",
    "* **1x1 Convolution**: Before applying MSE, the deeper layer’s output (layer4) is passed through a 1x1 convolution to match the number of channels with layer2.\n",
    "* **Interpolation**: The student’s layer2 feature map is resized to match the spatial dimensions of the deeper layer4 features.\n",
    "* **Alpha**: Balances the importance of distillation loss and cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eafe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SelfDistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(SelfDistillationLoss, self).__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.alpha = alpha  # Weight for self-distillation\n",
    "\n",
    "    def forward(self, student_logits, labels, student_intermediate, teacher_intermediate):\n",
    "        # Standard cross-entropy loss on the output logits\n",
    "        ce_loss = self.ce_loss(student_logits, labels)\n",
    "        \n",
    "        # Apply 1x1 convolution to teacher_intermediate to match the number of channels\n",
    "        teacher_intermediate_reduced = conv1x1(teacher_intermediate)\n",
    "        \n",
    "        # Resize the student_intermediate feature map to match teacher_intermediate's spatial size\n",
    "        student_intermediate_resized = F.interpolate(student_intermediate, size=teacher_intermediate_reduced.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Self-distillation loss (MSE between resized student intermediate outputs and teacher intermediate outputs)\n",
    "        distillation_loss = self.mse_loss(student_intermediate_resized, teacher_intermediate_reduced)\n",
    "        \n",
    "        # Combine the two losses\n",
    "        return self.alpha * distillation_loss + (1 - self.alpha) * ce_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f80eaf",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This function trains the student model using the self-distillation loss:\n",
    "\n",
    "* Training Loop: Iterates over the training data for a specified number of epochs (25 by default).\n",
    "* Forward Pass: For each batch, the model computes the outputs, and intermediate features are extracted via hooks.\n",
    "* Loss Computation: The total loss is computed by combining the cross-entropy loss and the self-distillation loss.\n",
    "* Backward Pass: The loss is used to perform backpropagation and update the model's weights.\n",
    "* Accuracy: Tracks the accuracy for each epoch, and the best model weights are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "badb9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the data\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the student model\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Get the intermediate feature maps\n",
    "            layer2_features = intermediate_features['layer2']\n",
    "            layer4_features = intermediate_features['layer4']\n",
    "\n",
    "            # Compute the loss (self-distillation loss)\n",
    "            loss = criterion(outputs, labels, layer2_features, layer4_features)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate epoch loss and accuracy\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "\n",
    "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Deep copy the model if it's the best so far\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d596bf2",
   "metadata": {},
   "source": [
    "## Optimizer and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7260991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Loss: 0.4253 Acc: 0.8775\n",
      "Epoch 1/4\n",
      "----------\n",
      "Loss: 0.2328 Acc: 0.9135\n",
      "Epoch 2/4\n",
      "----------\n",
      "Loss: 0.2063 Acc: 0.9139\n",
      "Epoch 3/4\n",
      "----------\n",
      "Loss: 0.1861 Acc: 0.9177\n",
      "Epoch 4/4\n",
      "----------\n",
      "Loss: 0.1656 Acc: 0.9272\n",
      "Training complete in 48m 9s\n",
      "Best Acc: 0.9272\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Define the self-distillation loss function\n",
    "criterion = SelfDistillationLoss(alpha=0.5)\n",
    "\n",
    "# Train the student model using self-distillation\n",
    "trained_student = train_student(student_model, dataloaders, criterion, optimizer, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e93093",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "This function evaluates the trained model on the validation set, computing the accuracy by comparing predictions to ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7e94252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloaders):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the trained student model\n",
    "evaluate_model(trained_student, dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370ecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
